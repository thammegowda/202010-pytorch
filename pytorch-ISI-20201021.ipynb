{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PyTorch \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep a tab open for pytorch docs : https://pytorch.org/docs/stable/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:device=cpu\n"
     ]
    }
   ],
   "source": [
    "import logging as log\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "\n",
    "log.basicConfig(level=log.INFO)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "log.info(f'device={device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchtext\n",
    "torchtext docs refer to https://pytorch.org/text/experimental_datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Downloading from Google Drive; may take a few minutes\n",
      "INFO:root:File /Users/tg/.torchtext/ag_news_csv.tar.gz already exists.\n",
      "INFO:root:Opening tar file /Users/tg/.torchtext/ag_news_csv.tar.gz.\n",
      "INFO:root:/Users/tg/.torchtext/ag_news_csv/train.csv already extracted.\n",
      "INFO:root:/Users/tg/.torchtext/ag_news_csv/test.csv already extracted.\n",
      "INFO:root:/Users/tg/.torchtext/ag_news_csv/classes.txt already extracted.\n",
      "INFO:root:/Users/tg/.torchtext/ag_news_csv/readme.txt already extracted.\n",
      "120000lines [00:01, 109193.04lines/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torchtext.experimental.datasets.text_classification.TextClassificationDataset,\n",
       " torchtext.experimental.datasets.text_classification.TextClassificationDataset)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchtext.experimental.datasets import YahooAnswers, DBpedia, AG_NEWS\n",
    "\n",
    "root = Path('~/.torchtext').expanduser()\n",
    "#train, test = YahooAnswers(root=root)\n",
    "#train, valid = DBpedia(root=root)\n",
    "train, valid = AG_NEWS(root=root)   # using this because it is small\n",
    "type(train), type(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Torch [data types](https://pytorch.org/docs/stable/tensors.html#torch-tensor)\n",
    "- [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor(3), tensor(4), tensor(4)]\n",
      "[tensor([10969,   489,     5,  2449,     8,    19,  1470,  1358,    47,    73,\n",
      "            6,   226,   520,     4,  4177,   477,  2046,  9704,    34,   742,\n",
      "            3,  1305,    13,    10, 10969,   489,    97,    21,  6231,   596,\n",
      "        52020,     2]), tensor([ 359, 1085,    5,    3, 1089,  359,   13,   10,   48,  953,    5,    3,\n",
      "        1089,   22,   69,    5,  291,    2,    3, 6445,    4, 2479,  548, 2685,\n",
      "        9273, 1439,   29, 2297,    3, 3290,  436,    3, 1089,    2]), tensor([ 1489,  1677,  1073,    21, 36112,   108,   108,  1374, 36112,    88,\n",
      "            2,     7,  2538,    36,  3361, 11344,     4,   163,    25,     6,\n",
      "        64226, 83619,    99,     5, 45212,     3,   869,     7,    23, 86632,\n",
      "        43650,  6866,     2])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = [], []\n",
    "    for label, txt in batch:\n",
    "        texts.append(txt)\n",
    "        labels.append(label)        \n",
    "    return texts, labels\n",
    "\n",
    "dataloader = DataLoader(train, batch_size=3, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "for idx, (texts, labels) in enumerate(dataloader):\n",
    "    print(idx, labels)\n",
    "    print(texts)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([4, 4, 4], dtype=torch.uint8) tensor([37, 24, 32], dtype=torch.int16)\n",
      "[tensor([ 1088,     5,   417,   223,     3,  6404,   580,   417,  3604,   234,\n",
      "           68,    17,  1001,  4037,    26,   318,    26,    22,  1088,    17,\n",
      "           10,  4129,   727,    22,    11,    23,    70,  8186,     2,  1088,\n",
      "           85,    68,    17,  1001, 45493,  1951,     2]), tensor([  189,   860,  7852,  2268,   242,  3397,    43,  6983,    19,   265,\n",
      "           18,    34,   970,   862,     5,  3140, 11945,  1669,     5,    41,\n",
      "          455,   286,   158,     2]), tensor([   99,  1151,  6438,  2225,  6231,    25,   601, 32515,  6002,     4,\n",
      "         1435,     2,    14,    32,    15,    54,     3,  6438,  2778,    18,\n",
      "          481,  1169,    39,  1130,  1577,  2216,    43,   278,  3000,     2,\n",
      "            2,     2])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = [], []\n",
    "    for label, txt in batch:\n",
    "        texts.append(txt)\n",
    "        labels.append(label) \n",
    "    \n",
    "    labels = torch.tensor(labels, dtype=torch.uint8)    \n",
    "    lengths = [len(txt) for txt in texts]\n",
    "    lengths = torch.tensor(lengths, dtype=torch.short)\n",
    "\n",
    "    return texts, labels, lengths\n",
    "\n",
    "dataloader = DataLoader(train, batch_size=3, collate_fn=collate_fn, shuffle=True)\n",
    "for idx, (texts, labels, lengths) in enumerate(dataloader):\n",
    "    print(idx, labels, lengths)\n",
    "    print(texts)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:vocabulary size= 95,812\n",
      "INFO:root:<unk>=0\n",
      "INFO:root:<pad>=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3: 30000, 4: 30000, 2: 30000, 1: 30000})\n"
     ]
    }
   ],
   "source": [
    "# vocabul\n",
    "train.vocab.itos[:10]\n",
    "PAD_IDX = train.vocab.stoi['<pad>']\n",
    "UNK_IDX = train.vocab.stoi['<unk>']\n",
    "log.info(f'vocabulary size= {len(train.vocab):,}')\n",
    "log.info(f'<unk>={UNK_IDX}')\n",
    "log.info(f'<pad>={PAD_IDX}')\n",
    "\n",
    "from collections import Counter\n",
    "all_labels = Counter(label for label, txt in train.data)\n",
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([4, 1, 3], dtype=torch.uint8) tensor([28, 25, 67], dtype=torch.int16)\n",
      "tensor([[ 5111,  1106,  6614,  3726,   333,     7, 16024,   964,    14,   405,\n",
      "            51,    15,   405,    51,    16,  1556,  7291,    25,  1929,   383,\n",
      "           105,  6011, 17553,   573,     4,   524,    85,     2,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1],\n",
      "        [  197,  3424,   161,   606,   122,   197,   564,    34,    38,  1227,\n",
      "             5,  1169,     3,   290,   235,    64,   271,    35,     6,  1661,\n",
      "           737,   122,    22,   859,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1],\n",
      "        [  152,  1782,   689,     4,   847,  2854,  6199,    24,    74,    14,\n",
      "            28,    15,    16,    52,     2,    10,     2,   152,  2522,   909,\n",
      "            11,    66,     4,   662,    25,   180,   220,   847,    65,     2,\n",
      "            42,     6,   260,   256,     2,   254,     2,    28,     2,   310,\n",
      "             2,   309,    81, 15186,     2,   372,   311,   847,     2,  1129,\n",
      "           258,     4,     6,   133,    35,    26,   187,     6,   281,   574,\n",
      "           154,     9,  1468,    31,  3246,   719,     2]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    texts, labels = [], []\n",
    "    for label, txt in batch:\n",
    "        texts.append(txt)\n",
    "        labels.append(label)\n",
    "\n",
    "    labels = torch.tensor(labels, dtype=torch.uint8)    \n",
    "    lengths = [len(txt) for txt in texts]\n",
    "    lengths = torch.tensor(lengths, dtype=torch.short)\n",
    "\n",
    "    seqs = torch.full(size=(len(texts), lengths.max()),\n",
    "                      fill_value=PAD_IDX, dtype=torch.long)\n",
    "    for idx, txt in enumerate(texts):\n",
    "        seqs[idx, :len(txt)] = txt\n",
    "    \n",
    "    return seqs, labels, lengths\n",
    "dataloader = DataLoader(train, batch_size=3, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "for idx, (texts, labels, lengths) in enumerate(dataloader):\n",
    "    print(idx, labels, lengths)\n",
    "    print(texts)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([2, 2, 1], dtype=torch.uint8) tensor([31, 35, 45], dtype=torch.int16)\n",
      "tensor([[   97,    17,    10,  1970,  2149,   910,  5452,  2492,   417,  1114,\n",
      "             2,   145,    14,    90,   218,    15,    21, 38271,   417,  3176,\n",
      "             4, 23193,     4,  6519,     2,     4,   442,   954,     2,   595,\n",
      "             2,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1],\n",
      "        [15393,  1155,    26,   503,   640,    26,    96,    13,  1532,    82,\n",
      "         27233,   157,   176,  2900, 15393,    87,     6,  1120,    48,   314,\n",
      "          3222,     2,     3,   250,  1550,    87,    82,   665,     4,    50,\n",
      "          2993, 11653,    12,    18,     2,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1],\n",
      "        [ 6791,  2264,    12,   147,     8,   486,   497,     3,    24,   169,\n",
      "           486,    34,   291,   377,    11,    56,    35,    23,  5859,    77,\n",
      "             4, 11977,  5766,  6791,     4,   193,     3,  6814,     7,  6198,\n",
      "           413,    12,    33,   112,    70,   116,    25,   565,   909,  4045,\n",
      "             5,     3,   169,  1262,     2]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Batch:\n",
    "    texts: torch.Tensor\n",
    "    labels: torch.Tensor\n",
    "    lengths: torch.Tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(seqs) \n",
    "\n",
    "    def tok_count():\n",
    "        return self.lengths.sum()\n",
    "\n",
    "    def to(self, device):\n",
    "        self.texts = self.texts.to(device)\n",
    "        self.labels = self.labels.to(device)\n",
    "        self.lengths = self.lengths.to(device)        \n",
    "        return self\n",
    "\n",
    "    def pin_memory(self):\n",
    "        self.texts = self.texts.pin_memory()\n",
    "        self.labels = self.labels.pin_memory()\n",
    "        self.lengths = self.lengths.pin_memory()        \n",
    "        return self\n",
    "\n",
    "    @classmethod\n",
    "    def collate_fn(cls, batch) -> 'Batch':\n",
    "        texts, labels = [], []\n",
    "        for label, txt in batch:\n",
    "            texts.append(txt)\n",
    "            labels.append(label)\n",
    "\n",
    "        labels = torch.tensor(labels, dtype=torch.uint8)    \n",
    "        lengths = [len(txt) for txt in texts]\n",
    "        lengths = torch.tensor(lengths, dtype=torch.short)\n",
    "\n",
    "        seqs = torch.full(size=(len(texts), lengths.max()),\n",
    "                          fill_value=PAD_IDX, dtype=torch.long)\n",
    "        for idx, txt in enumerate(texts):\n",
    "            seqs[idx, :len(txt)] = txt\n",
    "    \n",
    "        return cls(texts=seqs, labels=labels, lengths=lengths)\n",
    "\n",
    "dataloader = DataLoader(train, batch_size=3, collate_fn=Batch.collate_fn, shuffle=True, pin_memory=True)\n",
    "\n",
    "for idx, batch in enumerate(dataloader):\n",
    "    print(idx, batch.labels, batch.lengths)\n",
    "    print(batch.texts)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=Batch.collate_fn, pin_memory=True)\n",
    "valid_loader = DataLoader(valid, batch_size=BATCH_SIZE, shuffle=False, collate_fn=Batch.collate_fn, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/30000 [00:00<02:15, 220.22it/s, updates=100, epoch=0]\n",
      "INFO:root:Epoch 0 completed\n",
      "  0%|          | 99/30000 [00:00<02:01, 245.55it/s, updates=200, epoch=1]\n",
      "INFO:root:Epoch 1 completed\n",
      "  0%|          | 99/30000 [00:00<01:58, 253.27it/s, updates=300, epoch=2]\n",
      "INFO:root:Epoch 2 completed\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "steps = 100000\n",
    "\n",
    "count = 0\n",
    "epoch = 0\n",
    "while count < steps:\n",
    "    # https://github.com/tqdm/tqdm#documentation \n",
    "    with tqdm(train_loader, mininterval=0.2) as bar:\n",
    "        for batch in bar:\n",
    "            count += 1\n",
    "            bar.set_postfix(dict(updates=count, epoch=epoch))\n",
    "            if count % 100 == 0:  # testing \n",
    "                break\n",
    "    log.info(f'Epoch {epoch} completed')\n",
    "    epoch += 1\n",
    "    if epoch > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn                     # neural networks\n",
    "import torch.nn.functional as F           # layers, activations and more\n",
    "import torch.optim as optim\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Trainer:\n",
    "    model: nn.Module\n",
    "    opt: optim.Optimizer\n",
    "    #loss_func = nn.CrossEntropyLoss()      # object oriented API\n",
    "    loss_func = F.cross_entropy             # functional API \n",
    "\n",
    "# I use object-oriented API for components with states\n",
    "#    and functional API for stateless components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Trainer:\n",
    "    model: nn.Module\n",
    "    opt: optim.Optimizer = None\n",
    "    loss_func = F.cross_entropy\n",
    "\n",
    "    def validate(self, validate):\n",
    "        pass\n",
    "\n",
    "    def checkpoint(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, train_loader: DataLoader, valid_data: DataLoader, steps: int, checkpoint: int):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Trainer:\n",
    "    model: nn.Module\n",
    "    opt: optim.Optimizer = None\n",
    "    loss_func = F.cross_entropy\n",
    "    device = device\n",
    "\n",
    "    def __post_init__():\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        \n",
    "    def validate(self, validate) -> float:\n",
    "        pass\n",
    "\n",
    "    def checkpoint(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, train_loader: DataLoader, valid_data: DataLoader, steps: int, checkpoint: int):        \n",
    "        count = 0\n",
    "        epoch = 0\n",
    "        train_loss = 0\n",
    "        while count < steps:\n",
    "            with tqdm(train_loader) as databar:\n",
    "                for batch in databar:\n",
    "                    count += 1\n",
    "                    bar.set_postfix(dict(updates=count))\n",
    "                    \n",
    "            log.info(f'Epoch {epoch} completed')\n",
    "            epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.transformer import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "class TextClassifier(nn.Module):  # all modules should subclass nn.Module\n",
    "    \n",
    "    def __init__(self, vocab_size: int, n_classes: int, model_dim=256, n_heads=4, n_layers=4,\n",
    "                 ff_dim=1024, dropout=0.1, activation='relu'):\n",
    "        super().__init__() # remember to call super\n",
    "\n",
    "        self.embeddings = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                       embedding_dim=model_dim, padding_idx=PAD_IDX)\n",
    "        # TODO: positional encoding\n",
    "\n",
    "        enc_layer = TransformerEncoderLayer(d_model=model_dim, nhead=n_heads, dim_feedforward=ff_dim,\n",
    "                                                   dropout=dropout, activation=activation)\n",
    "        self.encoder = TransformerEncoder(enc_layer, num_layers=n_layers)\n",
    "        \n",
    "        self.cls_proj = nn.Linear(model_dim, n_classes)\n",
    "        \n",
    "    def forward(self, texts, lengths, out='probs'):\n",
    "        # [Batch x Length] --> [Batch x Length x HidDim]\n",
    "        embs = self.embeddings(texts)\n",
    "        # TODO: mask out the padding idxs\n",
    "\n",
    "        # some modules accept batch as second dimension\n",
    "        embs = embs.transpose(0, 1)            #[Length x Batch x HidDim]\n",
    "        feats = self.encoder(embs)\n",
    "        feats = feats.transpose(0, 1)          #[Batch x Length x HidDim]\n",
    "\n",
    "        #TODO: sentence representation\n",
    "        max_feats, max_indices = feats.max(dim=1, keepdim=False)  #[Batch x HidDim]\n",
    "        cls_logits = self.cls_proj(max_feats)       #[Batch x Classes]\n",
    "\n",
    "        return {'probs': F.softmax,\n",
    "         'log_probs': F.log_softmax, \n",
    "         'raw': lambda x: x\n",
    "        }[out](cls_logits)\n",
    "\n",
    "vocab = train.vocab\n",
    "n_classes = max(all_labels) + 1\n",
    "model_args = dict(vocab_size=len(vocab), n_classes=n_classes,\n",
    "                  model_dim=128, n_heads=2, n_layers=2, ff_dim=256)\n",
    "# Note: save model_args somewhere\n",
    "\n",
    "\n",
    "model = TextClassifier(**model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "\n",
    "    def __init__(self, model, lr=5e-4, device=device,\n",
    "                 opt=None, loss_func=None, lr_scheduler=None):\n",
    "        self.device = device        \n",
    "        self.model = model.to(self.device)\n",
    "        self.opt = opt or optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.loss_func = loss_func or F.cross_entropy\n",
    "        self.lr_scheduler = lr_scheduler\n",
    "        \n",
    "    def validate(self, valid_loader) -> float:\n",
    "        total = 0.\n",
    "        count = 0\n",
    "        for batch in valid_loader:\n",
    "            scores = self.model(texts=batch.texts, lengths=batch.lengths, out='raw')\n",
    "            loss = self.loss_func(input=scores, target=batch.labels.long(), reduction='mean')\n",
    "            total += loss.item()\n",
    "            count += 1\n",
    "        return total / count\n",
    "\n",
    "    def checkpoint(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, train_loader: DataLoader, valid_loader: DataLoader, steps: int, checkpoint: int):        \n",
    "        count = 0\n",
    "        epoch = 0\n",
    "        train_loss = 0.\n",
    "        self.model.train(True) #Training mode\n",
    "        while count < steps:\n",
    "            with tqdm(train_loader) as databar:\n",
    "                for idx, batch in enumerate(databar):\n",
    "\n",
    "                    scores = self.model(texts=batch.texts, lengths=batch.lengths, out='raw')\n",
    "                    # NOTE: loss_func accepts long values for target \n",
    "                    loss = self.loss_func(input=scores, target=batch.labels.long(), reduction='mean')\n",
    "\n",
    "                    loss.backward()\n",
    "                    self.opt.step()\n",
    "                    self.opt.zero_grad()\n",
    "\n",
    "                    loss_val = loss.detach().item()\n",
    "                    train_loss += loss_val \n",
    "\n",
    "                    count += 1\n",
    "                    databar.set_postfix(dict(updates=count, loss=loss_val), refresh=False)\n",
    "                    if count % checkpoint == 0:\n",
    "                        with torch.no_grad():\n",
    "                            self.model.train(False)\n",
    "                            val_loss = self.validate(valid_loader)\n",
    "                            train_loss /= checkpoint\n",
    "                            log.info(f'\\nCheckpoint at {count}; train_loss={train_loss:.4f} valid_loss={val_loss:.4f}')\n",
    "                            # TODO: checkpoint\n",
    "                            self.model.train(True)\n",
    "                            train_loss = 0\n",
    "            log.info(f'Epoch {epoch} completed')\n",
    "            epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 99/30000 [00:12<1:02:19,  8.00it/s, updates=99, loss=0.146] INFO:root:\n",
      "Checkpoint at 100; train_loss=0.6577 valid_loss=0.5691\n",
      "  1%|          | 199/30000 [00:31<1:02:02,  8.00it/s, updates=199, loss=1.39]  INFO:root:\n",
      "Checkpoint at 200; train_loss=0.5626 valid_loss=0.6243\n",
      "  1%|          | 299/30000 [00:49<59:53,  8.26it/s, updates=299, loss=1.62]    INFO:root:\n",
      "Checkpoint at 300; train_loss=0.6000 valid_loss=0.5624\n",
      "  1%|▏         | 399/30000 [01:07<1:00:30,  8.15it/s, updates=399, loss=1.45]  INFO:root:\n",
      "Checkpoint at 400; train_loss=0.6077 valid_loss=0.5467\n",
      "  2%|▏         | 499/30000 [01:26<1:00:54,  8.07it/s, updates=499, loss=1.23]  INFO:root:\n",
      "Checkpoint at 500; train_loss=0.5713 valid_loss=0.5664\n",
      "  2%|▏         | 599/30000 [01:45<1:02:35,  7.83it/s, updates=599, loss=0.152] INFO:root:\n",
      "Checkpoint at 600; train_loss=0.5854 valid_loss=0.5339\n",
      "  2%|▏         | 699/30000 [02:05<57:47,  8.45it/s, updates=699, loss=0.739]   INFO:root:\n",
      "Checkpoint at 700; train_loss=0.5891 valid_loss=0.5721\n",
      "  3%|▎         | 799/30000 [02:35<1:22:45,  5.88it/s, updates=799, loss=0.257]  Exception ignored in: <generator object tqdm.__iter__ at 0x7fba32dfb150>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tg/miniconda3/lib/python3.7/site-packages/tqdm/std.py\", line 1182, in __iter__\n",
      "    self.close()\n",
      "  File \"/Users/tg/miniconda3/lib/python3.7/site-packages/tqdm/std.py\", line 1270, in close\n",
      "    self._decr_instances(self)\n",
      "  File \"/Users/tg/miniconda3/lib/python3.7/site-packages/tqdm/std.py\", line 572, in _decr_instances\n",
      "    cls.monitor.exit()\n",
      "  File \"/Users/tg/miniconda3/lib/python3.7/site-packages/tqdm/_monitor.py\", line 53, in exit\n",
      "    self.join()\n",
      "  File \"/Users/tg/miniconda3/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/Users/tg/miniconda3/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-4337bf9376fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-181-fa9c10d9b361>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, valid_loader, steps, checkpoint)\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nCheckpoint at {count}; train_loss={train_loss:.4f} valid_loss={val_loss:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-181-fa9c10d9b361>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, valid_loader)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-aec41d477e74>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, texts, lengths, out)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# some modules accept batch as second dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m            \u001b[0;31m#[Length x Batch x HidDim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m          \u001b[0;31m#[Batch x Length x HidDim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0msrc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "trainer = Trainer(model=model)\n",
    "trainer.train(train_loader=train_loader, valid_loader=valid_loader, steps=10000, checkpoint=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
